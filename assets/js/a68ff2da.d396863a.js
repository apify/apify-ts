"use strict";(self.webpackChunk=self.webpackChunk||[]).push([[1890],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},c=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(n),m=r,h=d["".concat(s,".").concat(m)]||d[m]||u[m]||o;return n?a.createElement(h,i(i({ref:t},c),{},{components:n})):a.createElement(h,i({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},4959:(e,t,n)=>{n.d(t,{Z:()=>l});var a=n(7294),r=n(9960),o=n(4477),i=n(2263);const l=function(e){var t=e.to,n=e.children,l=(0,o.E)();return(0,i.default)().siteConfig.presets[0][1].docs.disableVersioning?a.createElement(r.default,{to:"/api/"+t},n):a.createElement(r.default,{to:"/api/"+("current"===l.version?"next":l.version)+"/"+t},n)}},6309:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>u,contentTitle:()=>p,default:()=>h,frontMatter:()=>s,metadata:()=>c,toc:()=>d});var a=n(7462),r=n(3366),o=(n(7294),n(3905)),i=n(4959),l=["components"],s={id:"setting-up",title:"Setting up",description:"Your first steps into the world of scraping with Crawlee"},p=void 0,c={unversionedId:"introduction/setting-up",id:"introduction/setting-up",title:"Setting up",description:"Your first steps into the world of scraping with Crawlee",source:"@site/../docs/introduction/01-setting-up.mdx",sourceDirName:"introduction",slug:"/introduction/setting-up",permalink:"/docs/introduction/setting-up",draft:!1,tags:[],version:"current",lastUpdatedBy:"Andrey Bykov",lastUpdatedAt:1657805876,formattedLastUpdatedAt:"7/14/2022",sidebarPosition:1,frontMatter:{id:"setting-up",title:"Setting up",description:"Your first steps into the world of scraping with Crawlee"},sidebar:"docs",previous:{title:"Introduction",permalink:"/docs/introduction/"},next:{title:"First crawler",permalink:"/docs/introduction/first-crawler"}},u={},d=[{value:"Creating a new project",id:"creating-a-new-project",level:3}],m={toc:d};function h(e){var t=e.components,n=(0,r.Z)(e,l);return(0,o.kt)("wrapper",(0,a.Z)({},m,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"To run Crawlee on your own computer, you need to meet the following pre-requisites first:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Have Node.js version 16.0 or higher installed.")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Visit ",(0,o.kt)("a",{parentName:"li",href:"https://nodejs.org/en/download/",target:"_blank",rel:"noopener"},"Node.js website")," to download or use ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/Schniz/fnm",target:"_blank",rel:"noopener"},"fnm"))),(0,o.kt)("ol",{start:2},(0,o.kt)("li",{parentName:"ol"},"Have NPM installed.")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"NPM comes bundled with Node.js, so you should already have it. If not, reinstall Node.js.",(0,o.kt)("blockquote",{parentName:"li"},(0,o.kt)("p",{parentName:"blockquote"},"Or use any other package manager of your choice.")))),(0,o.kt)("p",null,"If not certain, confirm the prerequisites by running:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"node -v\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"npm -v\n")),(0,o.kt)("h3",{id:"creating-a-new-project"},"Creating a new project"),(0,o.kt)("p",null,"The fastest and best way to create new projects with Crawlee is to use the ",(0,o.kt)("a",{parentName:"p",href:"https://www.npmjs.com/package/@crawlee/cli",target:"_blank",rel:"noopener"},"Crawlee CLI"),". This command line tool allows you to create and run Crawlee projects with ease. You can use the ",(0,o.kt)("inlineCode",{parentName:"p"},"npx")," utility to download and run the CLI - it is also embedded to the ",(0,o.kt)("inlineCode",{parentName:"p"},"crawlee")," meta-package:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"npx crawlee create my-new-project\n")),(0,o.kt)("p",null,"A prompt will be shown, asking you to choose a template. Let's choose the first one called ",(0,o.kt)("inlineCode",{parentName:"p"},"Crawlee playwright template [TypeScript]"),". The command will now create a new directory in your current working directory, called ",(0,o.kt)("inlineCode",{parentName:"p"},"my-new-project"),", create a ",(0,o.kt)("inlineCode",{parentName:"p"},"package.json")," in this folder and install all the necessary dependencies. It will also add example source code that you can immediately run."),(0,o.kt)("p",null,"Let's try that!"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"cd my-new-project\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"npx crawlee run\n")),(0,o.kt)("p",null,"We used the ",(0,o.kt)("inlineCode",{parentName:"p"},"crawlee run")," CLI command, but all what it actually does is to call ",(0,o.kt)("inlineCode",{parentName:"p"},"npm run start"),". You can use the ",(0,o.kt)("inlineCode",{parentName:"p"},"--script")," or ",(0,o.kt)("inlineCode",{parentName:"p"},"-s")," option to specify what script you want to run instead of the default ",(0,o.kt)("inlineCode",{parentName:"p"},"start"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"npx crawlee run --script=start:prod\n")),(0,o.kt)("div",{className:"admonition admonition-info alert alert--info"},(0,o.kt)("div",{parentName:"div",className:"admonition-heading"},(0,o.kt)("h5",{parentName:"div"},(0,o.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,o.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,o.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"}))),"Purging of storages")),(0,o.kt)("div",{parentName:"div",className:"admonition-content"},(0,o.kt)("p",{parentName:"div"},"Another option of the ",(0,o.kt)("inlineCode",{parentName:"p"},"crawlee run")," command is the control over purging: ",(0,o.kt)("inlineCode",{parentName:"p"},"--purge")," and more importantly ",(0,o.kt)("inlineCode",{parentName:"p"},"--no-purge"),", as purging is enabled by default. To understand what those are about, you first need to talk about the concept of storages in Crawlee. There are 3 types of a storage you can use: ",(0,o.kt)(i.Z,{to:"core/class/RequestQueue",mdxType:"ApiLink"},(0,o.kt)("inlineCode",{parentName:"p"},"RequestQueue")),", ",(0,o.kt)(i.Z,{to:"core/class/KeyValueStore",mdxType:"ApiLink"},(0,o.kt)("inlineCode",{parentName:"p"},"KeyValueStore"))," and ",(0,o.kt)(i.Z,{to:"core/class/Dataset",mdxType:"ApiLink"},(0,o.kt)("inlineCode",{parentName:"p"},"Dataset")),". Crawlee is using the first two for storing the runtime data about current crawl, and the third one is for storing the results."),(0,o.kt)("p",{parentName:"div"},"When Crawlee stores some state, it uses a storage - by default a ",(0,o.kt)(i.Z,{to:"memory-storage/class/MemoryStorage",mdxType:"ApiLink"},(0,o.kt)("inlineCode",{parentName:"p"},"MemoryStorage")),", which - contrary to its name - will also store the state in JSON files, so you can observe it easily. This state is being purged automatically when you run the crawler, and with the ",(0,o.kt)("inlineCode",{parentName:"p"},"--no-purge")," flag you can disable this behaviour and reuse the state you already have."),(0,o.kt)("p",{parentName:"div"},"More about storages and purging can be found in ",(0,o.kt)("a",{parentName:"p",href:"../guides/request-storage",target:null,rel:null},"Request Storage guide"),"."))),(0,o.kt)("p",null,"You should start seeing log messages in the terminal as the system boots up and after a second, a Chromium browser window should pop up. In the window, you'll see quickly changing pages and back in the terminal, you should see the titles (contents of the ",(0,o.kt)("inlineCode",{parentName:"p"},"<title>")," HTML tags) of the pages printed."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"We picked the playwright template, which will use the Chromium browser to open pages. If you picked the cheerio template instead, there won't be any browser window, as the requests to the target site will be done via ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/apify/got-scraping",target:"_blank",rel:"noopener"},(0,o.kt)("inlineCode",{parentName:"a"},"got-scraping"))," instead of real browser.")),(0,o.kt)("p",null,"You can always terminate the crawl with a keypress in the terminal:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"CTRL+C\n")))}h.isMDXComponent=!0}}]);