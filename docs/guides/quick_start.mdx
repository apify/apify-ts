---
id: quick-start
title: Quick Start
description: Quick and easy steps to get started using Crawlee today!
---

import ApiLink from '@site/src/components/ApiLink';

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';
import CodeBlock from '@theme/CodeBlock';

import CheerioSource from '!!raw-loader!./quick_start_cheerio.ts';
import PlaywrightSource from '!!raw-loader!./quick_start_playwright.ts';
import PuppeteerSource from '!!raw-loader!./quick_start_puppeteer.ts';

This short tutorial will set you up to start using Crawlee in a minute or two.
If you want to learn more, proceed to the [Getting Started](../guides/getting-started)
tutorial that will take you step by step through creating your first scraper.

## Local stand-alone usage

Crawlee requires [Node.js](https://nodejs.org/en/) 16 or later.
Add Crawlee to any Node.js project by running:

<Tabs groupId="quick_start">
<TabItem value="cheerio" label="CheerioCrawler" default>
<CodeBlock language="bash">npm install crawlee</CodeBlock>
</TabItem>
<TabItem value="playwright" label="PlaywrightCrawler">
<CodeBlock language="bash">npm install crawlee playwright</CodeBlock>

:::caution

`playwright` is not bundled with Crawlee to reduce install size and allow greater flexibility - thus we need to explicitly install it with NPM.

:::

</TabItem>
<TabItem value="puppeteer" label="PuppeteerCrawler">
<CodeBlock language="bash">npm install crawlee puppeteer</CodeBlock>

:::caution

`puppeteer` is not bundled with Crawlee to reduce install size and allow greater flexibility - thus we need to explicitly install it with NPM.

:::

</TabItem>
</Tabs>

Run the following example to perform a recursive crawl of a website using:

<Tabs groupId="quick_start">
    <TabItem value="cheerio" label="CheerioCrawler" default>
        <CodeBlock language="js" title="src/main.mjs">{CheerioSource}</CodeBlock>
    </TabItem>
    <TabItem value="playwright" label="PlaywrightCrawler">
        <CodeBlock language="js" title="src/main.mjs">{PlaywrightSource}</CodeBlock>
    </TabItem>
    <TabItem value="puppeteer" label="PuppeteerCrawler">
        <CodeBlock language="js" title="src/main.mjs">{PuppeteerSource}</CodeBlock>
    </TabItem>
</Tabs>

When you run the example, you should see Crawlee automating the data extraction process.

<Tabs groupId="quick_start">
<TabItem value="cheerio" label="CheerioCrawler" default>

:::danger TODO

Add CheerioCrawler gif here.

:::

</TabItem>
<TabItem value="playwright" label="PlaywrightCrawler">

:::danger TODO

Add PlaywrightCrawler gif here.

:::

</TabItem>
<TabItem value="puppeteer" label="PuppeteerCrawler">

![Chrome Scrape](/img/chrome_scrape.gif)

</TabItem>
</Tabs>

By default, Crawlee stores data to `./crawlee_storage` in the current working directory. You can override this behavior by setting the `CRAWLEE_STORAGE_DIR` environment variable. For details, see [Environment variables](../guides/environment-variables), [Request storage](../guides/request-storage) and [Result storage](../guides/result-storage).

For more examples showcasing various features of Crawlee, see the [Examples](../examples) section of the documentation.

## Local usage with Crawlee command-line interface (CLI)

To create a boilerplate of your project, you can use the [Crawlee command-line interface (CLI)](https://...) tool by running:

```bash
npx crawlee create my-hello-world
```

The CLI will prompt you to select a project boilerplate template - just pick "Hello world". The tool will create a directory called `my-hello-world` with a Node.js project files. You can run the project as follows:

```bash
cd my-hello-world
npm start
```

By default, the crawling data will be stored in a local directory at `./crawlee_storage`. For example, the input JSON file for the actor is expected to be in the default key-value store in `./crawlee_storage/key_value_stores/default/INPUT.json`.
